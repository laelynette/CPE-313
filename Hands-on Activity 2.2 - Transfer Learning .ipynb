{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f7bf401",
   "metadata": {},
   "source": [
    "#### **Castillo, Maria Antonette O.**\n",
    "#### **CPE32S8**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-sandwich",
   "metadata": {},
   "source": [
    "# Activity 2.2 - Transfer Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-fireplace",
   "metadata": {},
   "source": [
    "#### Objective(s):\n",
    "\n",
    "This activity aims to introduce how to apply transfer learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-elimination",
   "metadata": {},
   "source": [
    "#### Intended Learning Outcomes (ILOs):\n",
    "* Demonstrate how to build and train neural network \n",
    "* Demonstrate how to apply transfer learning in neural network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-azerbaijan",
   "metadata": {},
   "source": [
    "#### Resources:\n",
    "* Jupyter Notebook\n",
    "* CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-crime",
   "metadata": {},
   "source": [
    "#### Procedures\n",
    "Load the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "comic-joining",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import datetime\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-chair",
   "metadata": {},
   "source": [
    "Set the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sticky-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now\n",
    "batch_size = 128\n",
    "num_classes = 5\n",
    "epochs = 5\n",
    "img_rows, img_cols = 28, 28\n",
    "filters = 32\n",
    "pool_size = 2\n",
    "kernel_size = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-activity",
   "metadata": {},
   "source": [
    "Set how the input data is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "measured-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-russell",
   "metadata": {},
   "source": [
    "* Write a function to include all the training steps. \n",
    "* Use the model, training set, test set and number of classes as function parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "julian-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train, test, num_classes):\n",
    "    x_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
    "    x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(train[1], num_classes)\n",
    "    y_test = keras.utils.to_categorical(test[1], num_classes)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    t = now()\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))\n",
    "    print('Training time: %s' % (now() - t))\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3fc4bd",
   "metadata": {},
   "source": [
    "**The train model function includes reshaping of data to fit the input shape needs by the model, and convert the data type to float. For y_train and y_test, they are converted into one-hot encoded vectors. In addition, the model is compiled with the categorical cross-entropy loss function, adadelta optimizer, and accuracy metric. Then, the data is trained using the parameters batch size and number of epochs.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-final",
   "metadata": {},
   "source": [
    "Shuffle and split the data between train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hollywood-amendment",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-bench",
   "metadata": {},
   "source": [
    "Create two datasets \n",
    "* one with digits below 5\n",
    "* one with 5 and above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "lesser-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_lt5 = x_train[y_train < 5]\n",
    "y_train_lt5 = y_train[y_train < 5]\n",
    "x_test_lt5 = x_test[y_test < 5]\n",
    "y_test_lt5 = y_test[y_test < 5]\n",
    "\n",
    "x_train_gte5 = x_train[y_train >= 5]\n",
    "y_train_gte5 = y_train[y_train >= 5] - 5\n",
    "x_test_gte5 = x_test[y_test >= 5]\n",
    "y_test_gte5 = y_test[y_test >= 5] - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-scheme",
   "metadata": {},
   "source": [
    "* Define the feature layers that will used for transfer learning\n",
    "* Freeze these layers during fine-tuning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ranging-neutral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_layers = [\n",
    "    Conv2D(filters, kernel_size,\n",
    "           padding='valid',\n",
    "           input_shape=input_shape),\n",
    "    Activation('relu'),\n",
    "    Conv2D(filters, kernel_size),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-accuracy",
   "metadata": {},
   "source": [
    "Define the classification layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "religious-timer",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_layers = [\n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes),\n",
    "    Activation('softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-puzzle",
   "metadata": {},
   "source": [
    "Create a model by combining the feature layers and classification layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "governmental-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential(feature_layers + classification_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-dairy",
   "metadata": {},
   "source": [
    "Check the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "correct-syria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 26, 26, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 12, 12, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 12, 12, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               589952    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 600165 (2.29 MB)\n",
      "Trainable params: 600165 (2.29 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-regular",
   "metadata": {},
   "source": [
    " Train the  model on the digits 5,6,7,8,9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "distinct-ticket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (29404, 28, 28, 1)\n",
      "29404 train samples\n",
      "4861 test samples\n",
      "WARNING:tensorflow:From c:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "230/230 [==============================] - 14s 51ms/step - loss: 1.6085 - accuracy: 0.2331 - val_loss: 1.5932 - val_accuracy: 0.3283\n",
      "Epoch 2/5\n",
      "230/230 [==============================] - 11s 47ms/step - loss: 1.5836 - accuracy: 0.2980 - val_loss: 1.5646 - val_accuracy: 0.4855\n",
      "Epoch 3/5\n",
      "230/230 [==============================] - 11s 49ms/step - loss: 1.5558 - accuracy: 0.3747 - val_loss: 1.5340 - val_accuracy: 0.5501\n",
      "Epoch 4/5\n",
      "230/230 [==============================] - 11s 48ms/step - loss: 1.5289 - accuracy: 0.4395 - val_loss: 1.5006 - val_accuracy: 0.6104\n",
      "Epoch 5/5\n",
      "230/230 [==============================] - 11s 47ms/step - loss: 1.4965 - accuracy: 0.5008 - val_loss: 1.4633 - val_accuracy: 0.6750\n",
      "Training time: 0:00:57.564397\n",
      "Test score: 1.4633499383926392\n",
      "Test accuracy: 0.6749640107154846\n"
     ]
    }
   ],
   "source": [
    "train_model(model,\n",
    "            (x_train_gte5, y_train_gte5),\n",
    "            (x_test_gte5, y_test_gte5), num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-emission",
   "metadata": {},
   "source": [
    "Freeze only the feature layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "violent-territory",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for l in feature_layers:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-injection",
   "metadata": {},
   "source": [
    "Check again the summary and observe the parameters from the previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sunset-manhattan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 26, 26, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 12, 12, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 12, 12, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               589952    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 600165 (2.29 MB)\n",
      "Trainable params: 590597 (2.25 MB)\n",
      "Non-trainable params: 9568 (37.38 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-carnival",
   "metadata": {},
   "source": [
    "Train again the model using the 0 to 4 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "comprehensive-nurse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (30596, 28, 28, 1)\n",
      "30596 train samples\n",
      "5139 test samples\n",
      "Epoch 1/5\n",
      "240/240 [==============================] - 8s 25ms/step - loss: 1.5869 - accuracy: 0.2754 - val_loss: 1.5552 - val_accuracy: 0.4250\n",
      "Epoch 2/5\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.5430 - accuracy: 0.3578 - val_loss: 1.5074 - val_accuracy: 0.5184\n",
      "Epoch 3/5\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.4997 - accuracy: 0.4358 - val_loss: 1.4602 - val_accuracy: 0.6036\n",
      "Epoch 4/5\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.4577 - accuracy: 0.5084 - val_loss: 1.4148 - val_accuracy: 0.7210\n",
      "Epoch 5/5\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.4168 - accuracy: 0.5755 - val_loss: 1.3707 - val_accuracy: 0.8134\n",
      "Training time: 0:00:30.458924\n",
      "Test score: 1.3706990480422974\n",
      "Test accuracy: 0.8133878111839294\n"
     ]
    }
   ],
   "source": [
    "train_model(model,\n",
    "            (x_train_lt5, y_train_lt5),\n",
    "            (x_test_lt5, y_test_lt5), num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48090dbc",
   "metadata": {},
   "source": [
    "### **When digits more than or equal to 5 were trained, it resulted to an accuracy of approximately 67% and a loss of 1.46. Then, when the model's knowledge was transferred to learn another set of data which is 5 and below, the accuracy got higher at 81% and a loss of 1.37. This could mean that the initial training on previous digits provided a good foundation for learning the new dataset containing other digits.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-integer",
   "metadata": {},
   "source": [
    "#### Supplementary Activity\n",
    "Now write code to reverse this training process. That is, you will train on the digits 0-4, and then finetune only the last layers on the digits 5-9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ddae7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential(feature_layers + classification_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12dcf746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 26, 26, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 12, 12, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 12, 12, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               589952    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 600165 (2.29 MB)\n",
      "Trainable params: 590597 (2.25 MB)\n",
      "Non-trainable params: 9568 (37.38 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50e648a",
   "metadata": {},
   "source": [
    "### **The model's layers starts with two convolutional layers, each with 32 filters. These layers are followed by relu activation functions. Moreover, a max pooling layer is added to reduce their spatial dimensions to 12x12. Dropout layers are then used to randomly drop the neurons to prevent overfitting. The output of the max pooling layer is flattened into a one-dimensional vector. Next is 128 neurons in the first dense layer and number of classes in the output layer. Softmax is used for multiple classificattion. Overall, the model has a total of 600,165 parameters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "registered-venice",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_lt5 = x_train[y_train < 5]\n",
    "y_train_lt5 = y_train[y_train < 5]\n",
    "x_test_lt5 = x_test[y_test < 5]\n",
    "y_test_lt5 = y_test[y_test < 5]\n",
    "\n",
    "x_train_gte5 = x_train[y_train >= 5]\n",
    "y_train_gte5 = y_train[y_train >= 5] - 5  \n",
    "x_test_gte5 = x_test[y_test >= 5]\n",
    "y_test_gte5 = y_test[y_test >= 5] - 5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d369c17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (30596, 28, 28, 1)\n",
      "30596 train samples\n",
      "5139 test samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 7s 24ms/step - loss: 1.3763 - accuracy: 0.6332 - val_loss: 1.3286 - val_accuracy: 0.8593\n",
      "Epoch 2/5\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.3367 - accuracy: 0.6823 - val_loss: 1.2876 - val_accuracy: 0.8817\n",
      "Epoch 3/5\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.3000 - accuracy: 0.7231 - val_loss: 1.2470 - val_accuracy: 0.8943\n",
      "Epoch 4/5\n",
      "240/240 [==============================] - 5s 21ms/step - loss: 1.2612 - accuracy: 0.7601 - val_loss: 1.2071 - val_accuracy: 0.9041\n",
      "Epoch 5/5\n",
      "240/240 [==============================] - 5s 21ms/step - loss: 1.2233 - accuracy: 0.7835 - val_loss: 1.1683 - val_accuracy: 0.9087\n",
      "Training time: 0:00:28.426810\n",
      "Test score: 1.1683063507080078\n",
      "Test accuracy: 0.9087371230125427\n"
     ]
    }
   ],
   "source": [
    "train_model(model2,\n",
    "            (x_train_lt5, y_train_lt5),\n",
    "            (x_test_lt5, y_test_lt5), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3b4afe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in feature_layers:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206b7c66",
   "metadata": {},
   "source": [
    "**By setting the trainable to false, the neural network will not update the parameters of these specific layers during training. When we freezed the certain layers, it allows other parts of the model to be updated or fine-tuned on the new part of dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2715dba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (29404, 28, 28, 1)\n",
      "29404 train samples\n",
      "4861 test samples\n",
      "Epoch 1/5\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 1.4418 - accuracy: 0.4603 - val_loss: 1.4001 - val_accuracy: 0.5740\n",
      "Epoch 2/5\n",
      "230/230 [==============================] - 5s 22ms/step - loss: 1.4074 - accuracy: 0.5094 - val_loss: 1.3624 - val_accuracy: 0.6394\n",
      "Epoch 3/5\n",
      "230/230 [==============================] - 5s 22ms/step - loss: 1.3714 - accuracy: 0.5588 - val_loss: 1.3253 - val_accuracy: 0.6900\n",
      "Epoch 4/5\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 1.3362 - accuracy: 0.6043 - val_loss: 1.2894 - val_accuracy: 0.7280\n",
      "Epoch 5/5\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 1.3066 - accuracy: 0.6386 - val_loss: 1.2551 - val_accuracy: 0.7599\n",
      "Training time: 0:00:26.489872\n",
      "Test score: 1.2551113367080688\n",
      "Test accuracy: 0.7599259614944458\n"
     ]
    }
   ],
   "source": [
    "train_model(model2,\n",
    "            (x_train_gte5, y_train_gte5),\n",
    "            (x_test_gte5, y_test_gte5), num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426b1585",
   "metadata": {},
   "source": [
    "### **When the training process was reversed, the accuracy also got reversed. The initial training got the higher accuracy which is approximately 91% and a loss of 1.17. Meanwhile, the last layers that were finetuned on the digits 5-9 got a lower accuracy of approximately 76% and a loss of 1.26. This decrease in accuracy indicates that the model's performance on the digits 5-9 dataset was not that good after the fine-tuning process.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7e56b9",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-sapphire",
   "metadata": {},
   "source": [
    "### **Conclusion:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa18e1b",
   "metadata": {},
   "source": [
    "### **This activity helped me to explore the transfer learning on a neural network. This task showed that when the model was initially trained on digits 5 and above, it reached about 67% accuracy. Then, when it was transferred on digits below 5, the model improved at 81% accuracy. However, when the training was reversed, the results were not that good after fine-tuning on digits 5-9. Its accuracy dropped to around 76%. This means that the the order of training might have an effect on the model's performance in transfer learning.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
